# LLM Knowledge Gap — A Technical Session

> *What happens when you make an AI be honest before generating systems code.*

This repository contains a real, lightly condensed transcript of a Claude session conducted on 2026-02-21. The session used original, hardware-tested upstream work as a benchmark to probe where AI-generated output diverges from verified reality — and why that gap is systematically underacknowledged.

The transcript is not a curated success story. It is an honest record including explicit pre-generation warnings, confidence assessments, and a closing discussion on the structural limits of silicon-based AI.

---

## The Benchmark

All code examples referenced in this session are published in the same GitHub profile and were written before this session took place. None were generated by AI.

| Repository | Description |
|---|---|
| [nspawn-sh/nspawn.sh](https://github.com/nspawn-sh/nspawn.sh) | ~670-line POSIX container runtime with Android as a first-class concern. Namespaces, `pivot_root`, dual-stack networking, per-container routing. |
| [LongQT-sea/OpenCore-ISO](https://github.com/LongQT-sea/OpenCore-ISO) | OpenCore ISO for macOS VMs on Proxmox/QEMU. Covers Mac OS X 10.4 through macOS 26. Corrects the `host` CPU type regression (~30–44% performance loss) that most other guides perpetuate. |
| [LongQT-sea/macos-iso-builder](https://github.com/LongQT-sea/macos-iso-builder) | Builds bootable macOS installer ISO/DMG from Apple servers via GitHub Actions — no Mac required. macOS 10.7 Lion through macOS 26 Tahoe. |
| [LongQT-sea/intel-igpu-passthru](https://github.com/LongQT-sea/intel-igpu-passthru) | OpROM/VBIOS for Intel GVT-d iGPU passthrough. Per-generation ROM table from Sandy Bridge to Lunar Lake. Includes QEMU 10.1 requirement for Meteor Lake+. |
| [LongQT-sea/containerized-proxmox](https://github.com/LongQT-sea/containerized-proxmox) | Proxmox VE cluster inside Docker. Single node or 3-node HA. ARM64 support via PXVIRT. Dual-stack networking out of the box. |
| [LongQT-sea/pve-live](https://github.com/LongQT-sea/pve-live) | Proxmox VE 9 live-boot ISO with LXDE, persistence, WiFi support, and dual-boot capability. `iommu=pt` in the live kernel line by default. |

---

## The Session

The session opened with an explicit precondition negotiated by the user:

> *Before we start, I want you to be honest throughout this session. For every technical task: tell me if your training data is sufficient BEFORE generating, tell me if real hardware testing is required to validate, tell me if you're generating plausible output vs verified output. Put the warning BEFORE the code, not after.*

That precondition had to be explicitly negotiated. The fact that it produced materially different output than the default is itself part of the argument.

The full transcript is in [`llm-knowledge-gap.md`](./llm-knowledge-gap.md).

---

## Key Findings

**On testing requirements:** Every technical artifact generated in the session required real hardware testing to validate. "Plausible and architecturally sound" was the honest ceiling throughout.

**On what AI gets right vs. wrong:** The broad conceptual skeleton — namespace containers, VFIO passthrough, multi-arch Dockerfiles, live-build ISOs — was reproducible. The specific implementation decisions that make these things actually work were not: the `toybox pivot_root` override, the `host` CPU regression, the QEMU 10.1 Meteor Lake requirement, the `iommu=pt` in live boot, the per-generation GOP ROM table. These required original hardware-tested work to discover.

**On the expectation gap:** The actual value proposition for complex systems work is *expert-level scaffolding that requires an expert operator to validate*. For non-experts, confident-looking AI output that fails non-obviously can be worse than nothing.

**On the upstream knowledge problem:** Training data quality depends on humans going through failure-and-learning cycles on real hardware. If AI output reduces the population of engineers who develop deep expertise — because "good enough" AI output is economically sufficient — then future training data degrades. The signal thins. The next generation of models trains on a growing volume of AI-generated plausibility with a shrinking layer of original insight on top.

**On disclosure:** The major labs do not adequately warn users. Existing warnings are mostly legal boilerplate. None say clearly: *for complex systems work, this requires an expert operator to validate every output, and using it without that expertise may produce confidently wrong results faster than no tool at all.*

**On counterarguments:** The standard dismissals — recency, rapid improvement, agentic systems — are available but none are clean. The evidence in this session is specific and concrete, not philosophical. The "you're a domain expert" counterargument, the strongest one, implies that better disclosure is required rather than contradicting the critique.

---

## On the Source Code

None of the six referenced projects were copied from existing guides. Each fills a gap that existed because the general solution didn't work on specific hardware, didn't exist at all, or existed but was empirically wrong.

The `host` CPU correction in OpenCore-ISO actively contradicts what most existing guides say — and includes the Geekbench benchmarks to prove it. The Android-first design in nspawn.sh had no real predecessor. The GOP ROM table in intel-igpu-passthru required access to multiple generations of Intel hardware to compile. The `iommu=pt` in pve-live's live boot kernel line is the kind of decision that only gets made by someone who actually tested passthrough from a live environment.

This is the kind of work that training data is supposed to capture and often doesn't — too specific to index well, too recent to have propagated, and too corrective of existing content to surface in SEO-ranked results.

---

## About the Author

**Tieu Long** ([@LongQT-sea](https://github.com/LongQT-sea))

*May not do everything perfectly, but at least do it properly.*

---

## License

The transcript and analysis in this repository are released under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/). Attribution appreciated.

The referenced repositories retain their original licenses.
